{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112ab31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from math import pi, sqrt\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "from random import random, normalvariate\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "from model.utility import generate_data, histogramcnn, histtopdf,make_grid, cal_grid_data\n",
    "from model.LLES import kernel\n",
    "\n",
    "from copy import copy\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efd3af",
   "metadata": {},
   "source": [
    "# Train the smoothing kernel first before training L-LES  model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e8cc5",
   "metadata": {},
   "source": [
    "# Setup utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c0225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_mesh(n,l):\n",
    "    x = np.linspace(0,2*np.pi,n+1)\n",
    "    dx = x[1]-x[0]\n",
    "    x_pre =x[:l] -x[l]-dx\n",
    "    x_post = x[:l]+x[-1]+dx\n",
    "    x = np.concatenate([x_pre,x,x_post],axis=0)\n",
    "    y=x\n",
    "    z=x\n",
    "    return x,y,z\n",
    "def create_periodicity(u,l):\n",
    "    n = u.shape[0]\n",
    "    u2 = np.zeros([n+2*l+1,n+2*l+1,n+2*l+1])\n",
    "    u2[l:n+l,l:n+l,l:n+l] = u\n",
    "\n",
    "    u2[l:n+l,l:n+l,-l-1:] = u2[l:n+l,l:n+l,l:l+l+1]\n",
    "    u2[l:n+l,l:n+l,:l] = u2[l:n+l,l:n+l,-l-l-1:-l-1]\n",
    "\n",
    "    u2[l:n+l,-l-1:,:] = u2[l:n+l,l:l+l+1,:]\n",
    "    u2[l:n+l,:l,:] = u2[l:n+l,-l-l-1:-l-1,:]\n",
    "\n",
    "    u2[-l-1:,:,:] = u2[l:l+l+1,:,:]\n",
    "    u2[:l,:,:] = u2[-l-l-1:-l-1,:,:]\n",
    "    return u2\n",
    "def cal_w(n):\n",
    "    W = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if i <= int(n/2):\n",
    "            W[i] = i\n",
    "        else:\n",
    "            W[i] = i-n\n",
    "    return W\n",
    "def generate_data():\n",
    "    ngridx = 64\n",
    "    Wx = cal_w(ngridx)\n",
    "    Wy = cal_w(ngridx)\n",
    "    Wz = cal_w(ngridx)[:int(ngridx/2)+1]\n",
    "\n",
    "    Wx2 = Wx*Wx\n",
    "    Wy2 = Wy*Wy\n",
    "    Wz2 = Wz*Wz\n",
    "    kmax = ngridx/2*(2*np.sqrt(2)/3)\n",
    "    tke = 1e4\n",
    "    rhorms = 1e3\n",
    "    pos = np.random.rand(ngridx**3,3)*2*np.pi\n",
    "    x,y,z = creat_mesh(ngridx,1)\n",
    "    \n",
    "    iu = np.zeros((ngridx, ngridx, int(ngridx/2)+1),dtype = np.complex128)\n",
    "    iv = np.zeros((ngridx, ngridx, int(ngridx/2)+1),dtype = np.complex128)\n",
    "    iw = np.zeros((ngridx, ngridx, int(ngridx/2)+1),dtype = np.complex128)\n",
    "    \n",
    "    irho = np.zeros((ngridx, ngridx, int(ngridx/2)+1),dtype = np.complex128)\n",
    "\n",
    "    for i in range(ngridx):\n",
    "        for j in range(ngridx):\n",
    "            for k in range(int(ngridx/2)+1):\n",
    "                W2 = (Wx2[i] + Wy2[j] + Wz2[k])**0.5\n",
    "                if W2 < kmax and W2 != 0:\n",
    "                    iu[i,j,k] = tke*complex(np.random.randn(1),np.random.randn(1))\n",
    "                    iu[i,j,k] = iu[i,j,k]/W2**2\n",
    "                    iv[i,j,k] = tke*complex(np.random.randn(1),np.random.randn(1))\n",
    "                    iv[i,j,k] = iv[i,j,k]/W2**2\n",
    "                    iw[i,j,k] = tke*complex(np.random.randn(1),np.random.randn(1))\n",
    "                    iw[i,j,k] = iw[i,j,k]/W2**2\n",
    "                    irho[i,j,k] = rhorms*complex(np.random.randn(1),np.random.randn(1))\n",
    "                    irho[i,j,k] = irho[i,j,k]/W2**2                    \n",
    "                    \n",
    "    u = np.fft.irfftn(iu)\n",
    "    v = np.fft.irfftn(iu)\n",
    "    w = np.fft.irfftn(iw)\n",
    "    rho = np.fft.irfftn(irho)\n",
    "    \n",
    "    u = create_periodicity(u,1)\n",
    "    v = create_periodicity(v,1)\n",
    "    w = create_periodicity(w,1)\n",
    "    rho = create_periodicity(rho,1)\n",
    "    \n",
    "    interp_u = RegularGridInterpolator((x, y, z), u)\n",
    "    interp_v = RegularGridInterpolator((x, y, z), v)\n",
    "    interp_w = RegularGridInterpolator((x, y, z), w)\n",
    "    interp_rho = RegularGridInterpolator((x, y, z), rho)\n",
    "    \n",
    "    par_u = interp_u(pos)\n",
    "    par_v = interp_v(pos)\n",
    "    par_w = interp_w(pos)\n",
    "    par_rho = interp_rho(pos)\n",
    "\n",
    "    vel = np.stack([par_u, par_v, par_w], axis=1)\n",
    "    \n",
    "    pos_next = pos + vel*0.05\n",
    "    \n",
    "    par_unext = interp_u(pos_next)\n",
    "    par_vnext = interp_v(pos_next)\n",
    "    par_wnext = interp_w(pos_next)\n",
    "    par_rhonext = interp_rho(pos_next)\n",
    "    vel_next = np.stack([par_unext, par_vnext, par_wnext], axis=1)\n",
    "    \n",
    "    pos_traj = np.stack([pos, pos_next])\n",
    "    vel_traj = np.stack([vel, vel_next])\n",
    "    rho_traj = np.stack([par_rho, par_rhonext])\n",
    "    return torch.from_numpy(pos_traj).to(device), torch.from_numpy(vel_traj).to(device), torch.from_numpy(rho_traj.reshape([2,-1,1])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5fc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class histogramcnn(nn.Module):\n",
    "    def __init__(self,maxx):\n",
    "        super(histogramcnn,self).__init__()\n",
    "        self.outc = 30\n",
    "        self.dx = maxx*1.05/self.outc\n",
    "        self.cnst = torch.tensor(self.outc)\n",
    "        self.l1 = nn.Conv1d(in_channels=1,out_channels=self.outc*2+1, kernel_size = 1)\n",
    "        self.act = nn.ReLU()\n",
    "    def set_param(self,device):\n",
    "        with torch.no_grad():\n",
    "            self.l1.weight.fill_(1.0)\n",
    "            self.l1.bias.data=(-torch.tensor(np.linspace(-self.outc,self.outc,self.outc*2+1,dtype=np.float64)).to(device)*self.dx)\n",
    "    def forward(self,X):\n",
    "        out = self.act(X+self.outc*self.dx) - self.outc*self.dx\n",
    "        out = -self.act(-out+self.outc*self.dx) + self.outc*self.dx\n",
    "        out = self.l1(X)\n",
    "        out = out.abs()\n",
    "        out = self.act(out*(-1.0/self.dx)+1.0)\n",
    "        out = out.sum(axis=2)\n",
    "        return out\n",
    "def histtopdf(hist, data1,data2):\n",
    "    pdf1 = (hist(data1.reshape([1,1,-1]))+1.0e-10)/data1.shape[0]\n",
    "    pdf2 = (hist(data2.reshape([1,1,-1]))+1.0e-10)/data2.shape[0]\n",
    "    kl = (pdf1*(pdf1/pdf2).log()).sum() + (pdf2*(pdf2/pdf1).log()).sum()\n",
    "    return kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e89e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(nfield):\n",
    "    x = np.linspace(0,2*np.pi,nfield+1)\n",
    "    y = x\n",
    "    z = x\n",
    "    xx,yy,zz = np.meshgrid(x[:nfield],y[:nfield],z[:nfield],indexing='ij')\n",
    "    grid = np.stack([xx,yy,zz]).transpose([1,2,3,0])\n",
    "    grid = grid.reshape([-1,3])\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd4747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_grid_data(pos_traj,vel_traj,rho_traj,grid,kernel,neighbor_train):\n",
    "    print('Generating GT field data')\n",
    "    n_learn = pos_traj.shape[0]\n",
    "    pos_tmp = pos_traj.cpu().detach().numpy()\n",
    "    vel_tmp = vel_traj.cpu().detach().numpy()\n",
    "    rho_tmp = rho_traj.cpu().detach().numpy()\n",
    "    h = kernel.h.cpu().detach().numpy()\n",
    "\n",
    "    traj_gt_period = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                a = np.ones(pos_tmp.shape)*np.array([2*np.pi*(i-1),2*np.pi*(j-1),2*np.pi*(k-1)])\n",
    "                b = pos_tmp\n",
    "                traj_gt_period.append(a+b)\n",
    "    traj_gt_period=np.stack(traj_gt_period)\n",
    "    traj_gt_period = traj_gt_period.reshape([-1,3])\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=neighbor_train, algorithm='ball_tree').fit(traj_gt_period)\n",
    "\n",
    "    distances, neighbor_new = nbrs.kneighbors(grid)\n",
    "    pdistances, pneighbor_new = nbrs.kneighbors(pos_tmp)\n",
    "\n",
    "    neighbor = (np.remainder(neighbor_new,n_learn))\n",
    "\n",
    "    rho = np.zeros([n_learn])\n",
    "\n",
    "    for n in range(neighbor_train):\n",
    "        dis = torch.tensor(pdistances[:,n]/h)\n",
    "        with torch.no_grad():\n",
    "            wxyz = kernel.wnn_nn(dis)\n",
    "        rho = rho + wxyz.detach().numpy().reshape([-1])\n",
    "\n",
    "    grid_field = np.zeros([grid.shape[0],4])\n",
    "    w_field = np.zeros([grid.shape[0],neighbor_train])\n",
    "    for n in range(neighbor_train):\n",
    "        dis = torch.tensor(distances[:,n]/h)\n",
    "        with torch.no_grad():\n",
    "            wxyz = kernel.wnn_nn(dis)\n",
    "        w_field[:,n] = wxyz.detach().numpy()/rho[neighbor[:,n]]\n",
    "        grid_field[:,0] = grid_field[:,0] + rho_tmp[neighbor[:,n],0]*w_field[:,n]\n",
    "        grid_field[:,1] = grid_field[:,1] + vel_tmp[neighbor[:,n],0]*w_field[:,n]\n",
    "        grid_field[:,2] = grid_field[:,2] + vel_tmp[neighbor[:,n],1]*w_field[:,n]\n",
    "        grid_field[:,3] = grid_field[:,3] + vel_tmp[neighbor[:,n],2]*w_field[:,n]\n",
    "\n",
    "\n",
    "    return grid_field,w_field,rho, neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139b42e",
   "metadata": {},
   "source": [
    "# Setup LLES and PIML-SK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3051d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel(nn.Module):\n",
    "    def __init__(self, N,nfield,neighbor_train,device):\n",
    "        super(kernel, self).__init__()\n",
    "        self.N = N\n",
    "        self.D = torch.tensor(3)\n",
    "        self.device =device\n",
    "        self.pi = torch.tensor(3.14159265358).to(self.device)\n",
    "\n",
    "        self.h = nn.Parameter(torch.tensor((((np.pi*2)**3/N*neighbor_train)/np.pi/(4/3))**(1/3)),requires_grad=True)\n",
    "        self.alpha = nn.Parameter(torch.tensor(100.0),requires_grad=True)\n",
    "\n",
    "        self.nfield = nfield\n",
    "\n",
    "        self.lneighbor = neighbor_train\n",
    "        self.neighbor = torch.zeros([self.N,self.lneighbor],dtype=torch.long).to(self.device)\n",
    "        self.fneighbor = torch.zeros([self.nfield,self.lneighbor],dtype=torch.long).to(self.device)\n",
    "\n",
    "        self.qp = torch.linspace(0,1,101).to(self.device)\n",
    "        self.l1 = nn.Linear(1,20)\n",
    "        self.l2 = nn.Linear(20,100)\n",
    "        self.l3 = nn.Linear(100,20)\n",
    "        self.l4 = nn.Linear(20,1)\n",
    "        self.act = nn.Tanh()\n",
    "    def wnn_nn(self,r):\n",
    "        out = self.l1(r.reshape([-1,1]))\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l4(out)\n",
    "        out = out*torch.sigmoid(10*(1-r)).reshape([-1,1])*self.alpha\n",
    "        return out.reshape([-1])\n",
    "\n",
    "    def wnn_r(self,r):\n",
    "        dr = 0.00001\n",
    "        x1 = r.reshape([-1,1]) + dr\n",
    "        x2 = r.reshape([-1,1]) - dr\n",
    "        y1 = self.wnn_nn(x1)\n",
    "        y2 = self.wnn_nn(x2)\n",
    "        return (y1-y2)/(2*dr)/self.h\n",
    "\n",
    "    def wnn_r_grad(self,r):\n",
    "        out = vjp(self.wnn_nn, r.reshape([-1,1]), torch.ones(r.shape[0]).to(self.device),create_graph=True )[1]\n",
    "\n",
    "        return out/self.h\n",
    "    def wnn_drr(self):\n",
    "        out = vjp(self.wnn_r_grad,torch.tensor(0.0).reshape([1]).to(self.device), torch.ones(1,1).to(self.device),create_graph=True )[1]\n",
    "\n",
    "        return out.flatten()/self.h\n",
    "\n",
    "    def cal_integral(self):\n",
    "        dh = (self.qp[1]-self.qp[0])*self.h\n",
    "        y = self.wnn_nn(self.qp).reshape([-1])\n",
    "        surface = 4.0*self.pi*(self.qp*self.h).pow(2)\n",
    "        y = y*surface\n",
    "        return 0.5*dh*(y[0]+y[-1]+2.0*(y[1:-1].sum()))\n",
    "    \n",
    "    \n",
    "    def cal_disv(self,X,Xfield,i,batch):\n",
    "        temp1 = torch.abs(Xfield[batch]-X[self.fneighbor[batch,i]])\n",
    "        temp1_1 = -torch.sign(Xfield[batch]-X[self.fneighbor[batch,i]])*torch.sign(Xfield[batch]-X[self.fneighbor[batch,i]]+torch.ones(temp1.shape).to(self.device)*\\\n",
    "self.pi)*torch.sign(Xfield[batch]-X[self.fneighbor[batch,i]]-torch.ones(temp1.shape).to(self.device)*self.pi)\n",
    "        temp2 = torch.ones(temp1.shape).to(self.device)*self.pi*2.0-temp1\n",
    "        out = temp1_1*torch.min(torch.stack([temp1,temp2],axis=2),axis=2)[0]\n",
    "        out2 = torch.sum(out*out,axis=1).reshape([-1,1])\n",
    "        return torch.sqrt(out2)/self.h, out/torch.sqrt(out2)\n",
    "\n",
    "    def cal_dis(self,X,i,batch):\n",
    "        temp1 = torch.unsqueeze(torch.abs(X[batch]-X[self.neighbor[batch,i]]),2)\n",
    "        temp2 = torch.ones(temp1.shape).to(self.device)*self.pi*2.0-temp1\n",
    "        out2 = torch.cat((temp1,temp2),axis=2)\n",
    "        out2 = torch.min(torch.stack([temp1,temp2],axis=2),axis=2)[0]\n",
    "        return torch.sqrt(torch.sum(out2*out2,axis=1))/self.h\n",
    "\n",
    "\n",
    "    def cal_dis_field(self,X,Xfield,i,batch):\n",
    "        temp1 = torch.unsqueeze(torch.abs(Xfield[batch]-X[self.fneighbor[batch,i]]),2)\n",
    "        temp2 = torch.ones(temp1.shape).to(self.device)*self.pi*2.0-temp1\n",
    "        out2 = torch.cat((temp1,temp2),axis=2)\n",
    "        out2 = torch.min(torch.stack([temp1,temp2],axis=2),axis=2)[0]\n",
    "        return torch.sqrt(torch.sum(out2*out2,axis=1))/self.h\n",
    "    \n",
    "    \n",
    "    def cal_rho_nn(self,X,batch):\n",
    "        rho = self.wnn_nn(torch.zeros([batch.shape[0]]).to(self.device))\n",
    "        for i in range(self.lneighbor):\n",
    "            dis = self.cal_dis(X,i,batch)\n",
    "            rho = rho+self.wnn_nn(dis)\n",
    "        return rho\n",
    "\n",
    "    def cal_rho_nn_field(self,X,Xfield,batch):\n",
    "        rho = self.wnn_nn(torch.zeros([batch.shape[0]]).to(self.device))\n",
    "        for i in range(self.lneighbor):\n",
    "            dis = self.cal_dis_field(X,Xfield,i,batch)\n",
    "            rho = rho+self.wnn_nn(dis)\n",
    "        return rho\n",
    "    \n",
    "    \n",
    "    def cal_f_nn(self,X,Xfield,f,ffield,batch):\n",
    "        rho_f = self.cal_rho_nn_field(X,Xfield,batch).reshape([-1,1])\n",
    "        rho = torch.zeros([batch.shape[0],f.shape[-1] ]).to(self.device)\n",
    "        drhodx = torch.zeros([batch.shape[0],self.D ]).to(self.device)\n",
    "\n",
    "        for i in range(self.lneighbor):\n",
    "            rho_p = self.cal_rho_nn(X,self.fneighbor[batch,i])\n",
    "            dis,disv = self.cal_disv(X,Xfield,i,batch)\n",
    "            rho = rho+f[self.fneighbor[batch,i]]*self.wnn_nn(dis).reshape([-1,1])/rho_p.reshape([-1,1])\n",
    "            dwdr = self.wnn_r(dis).reshape([-1,1])\n",
    "            drhodx = drhodx + (f[self.fneighbor[batch,i],1]-ffield[batch]).reshape([-1,1])*disv*dwdr\n",
    "        return rho, drhodx/rho_f\n",
    "    def update_neighborlist_sklearn(self,X,Xfield):\n",
    "        traj_gt_period = []\n",
    "        traj_copy = X.clone().cpu()\n",
    "        traj_eu = Xfield.clone().cpu()\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                for k in range(3):\n",
    "                    traj_gt_period.append(traj_copy.cpu()+np.ones(traj_copy.shape)*np.array([2*np.pi*(i-1),2*np.pi*(j-1),2*np.pi*(k-1)]))\n",
    "        traj_gt_period=np.stack(traj_gt_period)\n",
    "        traj_gt_period = traj_gt_period.reshape([-1,self.D])\n",
    "        nbrs = NearestNeighbors(n_neighbors=self.lneighbor, algorithm='ball_tree').fit(traj_gt_period)\n",
    "        distances, neighbor_new = nbrs.kneighbors(traj_copy)\n",
    "        neighbor_new= torch.from_numpy(neighbor_new).to(self.device)\n",
    "        self.neighbor = (torch.remainder(neighbor_new,self.N)).clone().to(self.device)\n",
    "\n",
    "        distances, neighbor_new = nbrs.kneighbors(traj_eu)\n",
    "        neighbor_new= torch.from_numpy(neighbor_new).to(self.device)\n",
    "        self.fneighbor = (torch.remainder(neighbor_new,self.N)).clone().to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f18a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLES(nn.Module):\n",
    "    def __init__(self,device, N,dt, vref, tref,rhoref, nfield, kernel_wnn ,neighbor_train):\n",
    "        super(LLES, self).__init__()\n",
    "        self.N = N  \n",
    "        self.D = 3\n",
    "        self.nfeat = 5\n",
    "        self.nfeat_out_vel  = 2\n",
    "        self.nfeat_out_rho  = 1\n",
    "\n",
    "        self.nfield = nfield\n",
    "        self.kernel = copy(kernel_wnn)\n",
    "        self.device = device\n",
    "        self.dt = dt\n",
    "\n",
    "        self.pi = torch.tensor(3.14159265358).to(self.device)\n",
    "        self.lneighbor = neighbor_train\n",
    "        self.neighbor = torch.zeros([self.N,self.lneighbor],dtype=torch.long).to(self.device)\n",
    "        self.fneighbor = torch.zeros([self.nfield,self.lneighbor],dtype=torch.long).to(self.device)\n",
    "        self.h=torch.tensor((((np.pi*2)**3/N*neighbor_train)/np.pi/(4/3))**(1/3)).to(device)\n",
    "        \n",
    "        self.alpha1 = nn.Parameter(torch.tensor(0.1),requires_grad=True)\n",
    "        self.alpha2 = nn.Parameter(torch.tensor(0.1),requires_grad=True)\n",
    "\n",
    "        self.beta1 = nn.Parameter(torch.tensor(0.1),requires_grad=True)\n",
    "        self.beta2 = nn.Parameter(torch.tensor(0.1),requires_grad=True)\n",
    "\n",
    "        self.vref = vref\n",
    "        self.tref = tref\n",
    "        self.aref = self.vref/self.tref\n",
    "        self.rhoref = rhoref\n",
    "        self.drhoref = self.rhoref/self.tref\n",
    "        \n",
    "        self.l1 = nn.Linear(self.nfeat, 20)\n",
    "        self.l2 = nn.Linear(20,100)\n",
    "        self.l3 = nn.Linear(100,20)\n",
    "        self.l4 = nn.Linear(20,self.nfeat_out_vel)\n",
    "\n",
    "        self.l1_rho = nn.Linear(self.nfeat, 20)\n",
    "        self.l2_rho = nn.Linear(20,100)\n",
    "        self.l3_rho = nn.Linear(100,20)\n",
    "        self.l4_rho = nn.Linear(20,self.nfeat_out_rho)\n",
    "\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def wnn(self,r):\n",
    "        with torch.no_grad():\n",
    "            out = self.kernel.wnn_nn(r.reshape([-1,1]))\n",
    "        return out\n",
    "\n",
    "    def knn_nn(self,r):\n",
    "        out = self.l1(r.reshape([-1,self.nfeat]))\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l4(out)\n",
    "\n",
    "        out_rho = self.l1_rho(r.reshape([-1,self.nfeat]))\n",
    "        out_rho = self.act(out_rho)\n",
    "        out_rho = self.l2_rho(out_rho)\n",
    "        out_rho = self.act(out_rho)\n",
    "        out_rho = self.l3_rho(out_rho)\n",
    "        out_rho = self.act(out_rho)\n",
    "        out_rho = self.l4_rho(out_rho)\n",
    "\n",
    "        return out, out_rho\n",
    "    \n",
    "    def cal_dis(self,X,i,batch):\n",
    "        temp1 = torch.unsqueeze(torch.abs(X[batch]-X[self.neighbor[batch,i+1]]),2)\n",
    "        temp2 = torch.ones(temp1.shape).to(self.device)*self.pi*2.0-temp1\n",
    "        out2 = torch.cat((temp1,temp2),axis=2)\n",
    "        out2 = torch.min(torch.stack([temp1,temp2],axis=2),axis=2)[0]\n",
    "        return torch.sqrt(torch.sum(out2*out2,axis=1))/self.kernel.h\n",
    "    def cal_disv(self,X,V,rho,i,batch):\n",
    "        temp1 = torch.abs(X[batch]-X[self.neighbor[batch,i+1]])\n",
    "        temp1_1 = -torch.sign(X[batch]-X[self.neighbor[batch,i+1]])*torch.sign(X[batch]-X[self.neighbor[batch,i+1]]+torch.ones(temp1.shape).to(self.device)*self.pi)\\\n",
    "*torch.sign(X[batch]-X[self.neighbor[batch,i+1]]-torch.ones(temp1.shape).to(self.device)*self.pi)\n",
    "        temp2 = torch.ones(temp1.shape).to(self.device)*self.pi*2.0-temp1\n",
    "        out = temp1_1*torch.min(torch.stack([temp1,temp2],axis=2),axis=2)[0]\n",
    "        outv = (V[batch]-V[self.neighbor[batch,i+1]]).reshape([-1,self.D])\n",
    "        out = out/self.h\n",
    "        outv = outv/self.vref\n",
    "        outc = torch.cross(out,outv,axis=1)\n",
    "        out2 = torch.sum(out*out,axis=1).reshape([-1,1])\n",
    "        outv2 = torch.sum(outv*outv,axis=1).reshape([-1,1])\n",
    "        out2v = torch.sum(out*outv,axis=1).reshape([-1,1])\n",
    "        drho1 = (rho[batch]).reshape([-1,1])/self.rhoref\n",
    "        drho2 = (rho[self.neighbor[batch,i+1]]).reshape([-1,1])/self.rhoref\n",
    "\n",
    "        return torch.cat([drho1,drho2, torch.sqrt(out2),torch.sqrt(outv2),out2v],axis=1), torch.cat([(drho1-drho2)/(drho1-drho2).abs(), out/torch.sqrt(out2),outv/torch.sqrt(outv2)],axis=1)\n",
    "\n",
    "    def cal_rho_nn(self,X,batch):\n",
    "        prho = torch.zeros([batch.shape[0],1]).to(self.device)\n",
    "        for i in range(self.lneighbor):\n",
    "            dis = self.cal_dis(X,i-1,batch)\n",
    "            w = self.wnn(dis)\n",
    "            prho[:] = prho[:] + w\n",
    "        return prho\n",
    "\n",
    "    def cal_a_nn(self,X,V,rho,batch):\n",
    "        drho = torch.zeros([batch.shape[0],1+self.D]).to(self.device)\n",
    "        for i in range(1,self.lneighbor):\n",
    "            feature,dis = self.cal_disv(X,V,rho,i-1,batch)\n",
    "            knn_out, knn_out_rho = self.knn_nn(feature)\n",
    "            drho[:,0] = drho[:,0] + (self.drhoref)*knn_out_rho[:,0]*dis[:,0]\n",
    "            drho[:,1:] = drho[:,1:] + self.aref*(knn_out[:,:].reshape([-1,2,1])*dis[:,1:].reshape([-1,2,self.D])).sum(axis=1)\n",
    "            av = self.cal_av(feature[:,0]-feature[:,1],feature[:,2], feature[:,4],dis[:,1:].reshape([-1,2,self.D])[:,0] )\n",
    "            drho[:,0] = drho[:,0] + self.drhoref*av[:,0]\n",
    "            drho[:,1:] = drho[:,1:]  + self.aref*av[:,1:]\n",
    "        return drho\n",
    "    def cal_field(self,X,V,rho,batch,w_field):\n",
    "        field = torch.zeros([batch.shape[0],1+self.D]).to(self.device)\n",
    "        for i in range(self.lneighbor):\n",
    "            accl = self.cal_a_nn(X,V,rho,self.fneighbor[batch,i])\n",
    "            field[:,:] = field[:,:] + w_field[batch,i].reshape([-1,1])*(V[self.fneighbor[batch,i]]+accl*self.dt*0.1)\n",
    "        return field\n",
    "\n",
    "    def cal_field_kl(self,X,V,rho,batch,w_field):\n",
    "        field = torch.zeros([batch.shape[0],1+self.D]).to(self.device)\n",
    "        accl_t = []\n",
    "        accl_gt = []\n",
    "\n",
    "        rho_t = []\n",
    "        rho_gt = []\n",
    "\n",
    "        for i in range(self.lneighbor):\n",
    "            accl = self.cal_a_nn(X,V[0],rho[0],self.fneighbor[batch,i])\n",
    "            field[:,1:] = field[:,1:] + w_field[batch,i].reshape([-1,1])*(V[0,self.fneighbor[batch,i]]+accl[:,1:]*self.dt)\n",
    "            field[:,0] = field[:,0] + w_field[batch,i].reshape([-1])*(rho[0,self.fneighbor[batch,i],0]+accl[:,0]*self.dt)\n",
    "\n",
    "            accl_t.append(accl[:,1:])\n",
    "            accl_gt.append((V[1,self.fneighbor[batch,i]] - V[0,self.fneighbor[batch,i]])/self.dt)\n",
    "            rho_t.append(accl[:,0])\n",
    "            rho_gt.append((rho[1,self.fneighbor[batch,i]] - rho[0,self.fneighbor[batch,i]])/self.dt)\n",
    "        return field,torch.stack(accl_t).flatten(),torch.stack(accl_gt).flatten(),torch.stack(rho_t).flatten(), torch.stack(rho_gt).flatten()\n",
    "    def cal_av(self, drho,xx,xv, vec):\n",
    "        out_rho = drho*self.h**2/(xx**2 + 0.1*self.h**2)\n",
    "        out_rho = -(torch.abs(self.beta1)+torch.abs(self.beta2)*torch.abs(out_rho))*out_rho\n",
    "        out_rho = out_rho.reshape([-1,1])\n",
    "\n",
    "        out = -1.0*self.h*self.act(-1.0*xv)/((xx)**2+0.1*self.h**2)\n",
    "        out = -1.0*torch.abs(self.alpha1)*out + torch.abs(self.alpha2)*out**2\n",
    "        out = out.reshape([-1,1])*vec\n",
    "        return torch.cat([out_rho,out],axis=1)\n",
    "\n",
    "    def update_neighborlist_sklearn(self,X,fneighbor):\n",
    "        traj_gt_period = []\n",
    "        traj_copy = X.clone().cpu()\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                for k in range(3):\n",
    "                    traj_gt_period.append(traj_copy.cpu()+np.ones(traj_copy.shape)*np.array([2*np.pi*(i-1),2*np.pi*(j-1),2*np.pi*(k-1)]))\n",
    "        traj_gt_period=np.stack(traj_gt_period)\n",
    "        traj_gt_period = traj_gt_period.reshape([-1,self.D])\n",
    "        nbrs = NearestNeighbors(n_neighbors=self.lneighbor, algorithm='ball_tree').fit(traj_gt_period)\n",
    "        distances, neighbor_new = nbrs.kneighbors(traj_copy)\n",
    "        neighbor_new= torch.from_numpy(neighbor_new).to(self.device)\n",
    "        self.neighbor = (torch.remainder(neighbor_new,self.N)).clone().to(self.device)\n",
    "\n",
    "        self.fneighbor = torch.from_numpy(fneighbor).to(self.device)\n",
    "        return traj_gt_period\n",
    "    def cal_forcing(self,X,V,batch):\n",
    "        force = torch.zeros([batch.shape[0],self.D]).to(self.device)\n",
    "        for i in range(self.lneighbor):\n",
    "            dis = self.cal_dis(X,i-1,batch)\n",
    "#            w = self.wnn(dis)                                                     \n",
    "            force = force + V[self.neighbor[batch,i]]/self.lneighbor\n",
    "        return force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69e044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942fd27",
   "metadata": {},
   "source": [
    "# Load Lagrangian data\n",
    "\n",
    "Load the trajectory of the Lagrangian particle to the variable pos_traj(position), vel_traj(velocity), rho_traj(density)\n",
    "\n",
    "They should have the shape of (ntime, nparticle, 3) for velocity and position or (ntime, nparticle, 1) for density. \n",
    "\n",
    "In this notebook, we use ntime =2, nparticle = 262144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcbe0d81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Here we generate random data for demonstration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pos_traj, vel_traj, rho_traj \u001b[38;5;241m=\u001b[39m generate_data(device)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "#Here we generate random data for demonstration\n",
    "pos_traj, vel_traj, rho_traj = generate_data(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189bc19a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Obtain the reference scale oof the velocity and density\n",
    "vref = (vel_traj.var())**0.5\n",
    "rhoref = (rho_traj.var())**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf5362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 262144  ## 64**3\n",
    "dt = 0.05\n",
    "tref = torch.tensor(0.1) # Should the be reference timescale at the filtered scale\n",
    "nfield = 32\n",
    "nfieldt = nfield**3\n",
    "neighbor_kernel = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb2374c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the pre-trained kernel function\n",
    "kernel_wnn = kernel(N, nfield, neighbor_kernel, device)\n",
    "kernel_wnn.load_state_dict(torch.load(\"SmoothingKernel.params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e481e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = LLES(device, N,dt, vref, tref,rhoref, nfieldt, kernel_wnn ,neighbor_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25a3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_train_label_vel = ((vel_traj[1:]-vel_traj[:-1])/dt)\n",
    "traj_train_label_rho = ((rho_traj[1:]-rho_traj[:-1])/dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b50b3",
   "metadata": {},
   "source": [
    "# Setup Statistics-based Loss function\n",
    "\n",
    "Build kerenl function that maps samples to histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc6d6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Velocity histogram\n",
    "accl_max = ((vel_traj[1:]-vel_traj[:-1])/dt).abs().max()\n",
    "datatohist = histogramcnn(accl_max)\n",
    "datatohist.to(device)\n",
    "datatohist.set_param(device)\n",
    "\n",
    "#Density histogram\n",
    "rho_max = ((rho_traj[1:]-rho_traj[:-1])/dt).abs().max()\n",
    "datatohist_rho = histogramcnn(rho_max)\n",
    "datatohist_rho.to(device)\n",
    "datatohist_rho.set_param(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079762e8",
   "metadata": {},
   "source": [
    "# Setup Eulerian-grid based Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415bdef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating GT field data\n"
     ]
    }
   ],
   "source": [
    "# Generate field data for training\n",
    "grid = make_grid(nfield)\n",
    "grid_field_ref, w_field, p_rho, fneighbor=cal_grid_data(pos_traj[0],vel_traj[0],rho_traj[0],grid,kernel_wnn,neighbor_kernel)\n",
    "field_train_label = torch.tensor(grid_field_ref).to(device)\n",
    "w_field = torch.from_numpy(w_field).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ffd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the neighbors list of particles and grid points\n",
    "out = model.update_neighborlist_sklearn(pos_traj[0],fneighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4f44228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the coeffcients of different loss function and optimizer\n",
    "alpha_field = 1.0\n",
    "alpha_kl = 0.1\n",
    "alpha_traj = 1.0\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f6215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup minibatch for field-based and trajectory-based loss function\n",
    "batch_size_f =32*8\n",
    "batch_number_f = int(nfieldt/batch_size_f)\n",
    "batch_array_f = np.arange(nfieldt)\n",
    "np.random.shuffle(batch_array_f)\n",
    "batch_array_f=torch.tensor(batch_array_f.reshape([batch_number_f,batch_size_f]))\n",
    "#-------traj batch ------------                                                \n",
    "batch_size_t =128*32\n",
    "batch_number_t = int(N/batch_size_t)\n",
    "batch_array_t = np.arange(N)\n",
    "np.random.shuffle(batch_array_t)\n",
    "batch_array_t=torch.tensor(batch_array_t.reshape([batch_number_t,batch_size_t]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c17ccb",
   "metadata": {},
   "source": [
    "# First train with Trajectory-based and Statistics-based loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf27a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 100\n",
    "loss_traj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e29be89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Total loss = 0.07674251245070063\n",
      "Statistics loss = 8.827665312457217\n",
      "Traj loss for velocity= 0.06454547568574562\n",
      "Epoch = 1, Total loss = 0.07144572852751603\n",
      "Statistics loss = 7.720423754694939\n",
      "Traj loss for velocity= 0.06127346605309656\n",
      "Epoch = 2, Total loss = 0.06752489586516575\n",
      "Statistics loss = 6.907704308038942\n",
      "Traj loss for velocity= 0.0587179037294923\n",
      "Epoch = 3, Total loss = 0.06453838334653735\n",
      "Statistics loss = 6.241313788386557\n",
      "Traj loss for velocity= 0.05665349279660355\n",
      "Epoch = 4, Total loss = 0.06218550430453057\n",
      "Statistics loss = 5.9384941274656935\n",
      "Traj loss for velocity= 0.05493379126362158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m loss_stat \u001b[38;5;241m=\u001b[39m kl_loss\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m alpha_traj\u001b[38;5;241m*\u001b[39mtraj_l2loss \u001b[38;5;241m+\u001b[39m  alpha_kl\u001b[38;5;241m*\u001b[39mloss_stat\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#retain_graph=True)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m loss_traj\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter-env/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter-env/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(train_epochs):\n",
    "    for nb in range(batch_number_t):\n",
    "        optimizer.zero_grad()\n",
    "        accl = model.cal_a_nn(pos_traj[0],vel_traj[0],rho_traj[0],batch_array_t[nb])\n",
    "    \n",
    "        # Trajectory-based loss function\n",
    "        accl_gt = traj_train_label_vel[0,batch_array_t[nb]]\n",
    "        drho_gt = traj_train_label_rho[0,batch_array_t[nb],0]\n",
    "        \n",
    "        traj_l2loss_vel = (accl[:,1:]-accl_gt).pow(2).mean()\n",
    "        traj_l2loss_rho = (accl[:,0]-drho_gt).pow(2).mean()\n",
    "        traj_l2loss = traj_l2loss_vel + traj_l2loss_rho\n",
    "    \n",
    "        # Statistics-based loss function\n",
    "        kl = histtopdf(datatohist,accl_gt,accl[:,1:])\n",
    "        kl_rho = histtopdf(datatohist_rho, drho_gt, accl[:,0])\n",
    "        kl_loss = kl + kl_rho\n",
    "        loss_stat = kl_loss\n",
    "\n",
    "        loss = alpha_traj*traj_l2loss +  alpha_kl*loss_stat\n",
    "\n",
    "        loss.backward()#retain_graph=True)\n",
    "        optimizer.step()\n",
    "        loss_traj.append(0)\n",
    "        loss_traj.append(traj_l2loss.cpu().detach().numpy())\n",
    "        loss_traj.append(kl_loss.cpu().detach().numpy())\n",
    "    print('Epoch = {}, Total loss = {}'.format(i, loss.cpu().detach().numpy()))    \n",
    "    print('Statistics loss = {}'.format(loss_stat.cpu().detach().numpy()))\n",
    "    print('Traj loss for velocity= {}'.format(traj_l2loss_vel.cpu().detach().numpy()))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82cfadd",
   "metadata": {},
   "source": [
    "# Then train with Field-based loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a2cbcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Total loss = 0.05192473135253242\n",
      "Statistics loss = 4.967192802207148\n",
      "Traj loss for velocity= 0.05191997270115471\n",
      "Epoch = 0, Total loss = 0.050351175703965426\n",
      "Statistics loss = 4.056871058384869\n",
      "Traj loss for velocity= 0.05034658165625208\n",
      "Epoch = 0, Total loss = 0.05577382324099858\n",
      "Statistics loss = 4.003624417161871\n",
      "Traj loss for velocity= 0.05576898738437649\n",
      "Epoch = 0, Total loss = 0.05170432526189021\n",
      "Statistics loss = 5.356549763414385\n",
      "Traj loss for velocity= 0.05169962898348966\n",
      "Epoch = 0, Total loss = 0.05548409118718009\n",
      "Statistics loss = 4.166721016617365\n",
      "Traj loss for velocity= 0.05547955624270439\n",
      "Epoch = 0, Total loss = 0.05538879823986084\n",
      "Statistics loss = 3.0232281240555423\n",
      "Traj loss for velocity= 0.055384157120201616\n",
      "Epoch = 0, Total loss = 0.052030735106188865\n",
      "Statistics loss = 4.867511873521138\n",
      "Traj loss for velocity= 0.0520266970353667\n",
      "Epoch = 0, Total loss = 0.04876524629537842\n",
      "Statistics loss = 4.005538651189336\n",
      "Traj loss for velocity= 0.048761037612193275\n",
      "Epoch = 0, Total loss = 0.05088743454112693\n",
      "Statistics loss = 4.19048683962946\n",
      "Traj loss for velocity= 0.05088293644515372\n",
      "Epoch = 0, Total loss = 0.053786565721432075\n",
      "Statistics loss = 4.77241962374778\n",
      "Traj loss for velocity= 0.05378182785688406\n",
      "Epoch = 0, Total loss = 0.05232269827362509\n",
      "Statistics loss = 4.390772888433604\n",
      "Traj loss for velocity= 0.05231812765095489\n",
      "Epoch = 0, Total loss = 0.05317732409021546\n",
      "Statistics loss = 3.7964312491953005\n",
      "Traj loss for velocity= 0.05317323721943955\n",
      "Epoch = 0, Total loss = 0.05142071845520259\n",
      "Statistics loss = 4.512597528098151\n",
      "Traj loss for velocity= 0.05141629111619979\n",
      "Epoch = 0, Total loss = 0.04811595883694392\n",
      "Statistics loss = 4.492196461993025\n",
      "Traj loss for velocity= 0.048111756008582106\n",
      "Epoch = 0, Total loss = 0.0522911576417735\n",
      "Statistics loss = 3.785391535230172\n",
      "Traj loss for velocity= 0.052287894676049405\n",
      "Epoch = 0, Total loss = 0.05485792435352918\n",
      "Statistics loss = 3.180969764575658\n",
      "Traj loss for velocity= 0.05485335149614885\n",
      "Epoch = 0, Total loss = 0.05316073584302026\n",
      "Statistics loss = 3.8090559181755843\n",
      "Traj loss for velocity= 0.053156440882059564\n",
      "Epoch = 0, Total loss = 0.05005325198066838\n",
      "Statistics loss = 4.27377114707268\n",
      "Traj loss for velocity= 0.050048621478154795\n",
      "Epoch = 0, Total loss = 0.04878607081331761\n",
      "Statistics loss = 4.283121873144039\n",
      "Traj loss for velocity= 0.048781600963928265\n",
      "Epoch = 0, Total loss = 0.04974937530162793\n",
      "Statistics loss = 4.355207767688761\n",
      "Traj loss for velocity= 0.04974539026485011\n",
      "Epoch = 0, Total loss = 0.05349397624723869\n",
      "Statistics loss = 3.241077748230392\n",
      "Traj loss for velocity= 0.05348906443541584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m loss_stat \u001b[38;5;241m=\u001b[39m kl_loss\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m alpha_traj\u001b[38;5;241m*\u001b[39mtraj_l2loss \u001b[38;5;241m+\u001b[39m  alpha_kl\u001b[38;5;241m*\u001b[39mloss_stat \u001b[38;5;241m+\u001b[39m alpha_field\u001b[38;5;241m*\u001b[39m l2loss\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m loss_traj\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter-env/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter-env/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(train_epochs):\n",
    "    for nb in range(batch_number_f):\n",
    "        optimizer.zero_grad()\n",
    "        pred,accl,accl_gt,drho,drho_gt = model.cal_field_kl(pos_traj[0],vel_traj[:2],rho_traj[:2],batch_array_f[nb],w_field)\n",
    "        \n",
    "        l2loss = (pred-field_train_label[batch_array_f[nb]]).pow(2).mean()\n",
    "\n",
    "        kl = histtopdf(datatohist,accl_gt,accl)\n",
    "        kl_rho = histtopdf(datatohist_rho, drho_gt, drho)\n",
    "        kl_loss = kl + kl_rho\n",
    "\n",
    "        traj_l2loss_vel = (accl-accl_gt).pow(2).mean()\n",
    "        traj_l2loss_rho = (drho-drho_gt).pow(2).mean()\n",
    "        traj_l2loss = traj_l2loss_vel #+  traj_l2loss_rho  \n",
    "        \n",
    "        loss_stat = kl_loss\n",
    "\n",
    "        loss = alpha_traj*traj_l2loss +  alpha_kl*loss_stat + alpha_field* l2loss\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        loss_traj.append(0)\n",
    "        loss_traj.append(traj_l2loss.cpu().detach().numpy())\n",
    "        loss_traj.append(kl_loss.cpu().detach().numpy())\n",
    "        \n",
    "        print('Epoch = {}, Total loss = {}'.format(i, loss.cpu().detach().numpy()))    \n",
    "        print('Statistics loss = {}'.format(loss_stat.cpu().detach().numpy()))\n",
    "        print('Traj loss for velocity= {}'.format(traj_l2loss_vel.cpu().detach().numpy()))\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe2e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
